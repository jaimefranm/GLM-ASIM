import library_part as TFGimport numpy as npimport pickleimport os# Just for plot presentation in LaTeX Style (slows the program)#plt.rc('font', **{'family': 'serif', 'serif': ['latin modern roman']})'''#####################################################               USER INPUT DATA                 #####################################################'''### GENERAL #### Boolean variable for setting everything for the first executionfirst_execution = True# Boolean variable for generating plotsshow_plots = False# Boolean variable for pre-cross-correlated datapre_xc = True# Boolean variable for pre-oredered triggers in directoriespre_trigger_directories = True# Path to Hard Disk (with all MMIA files and where to store all files)#ssd_path = '/Volumes/Jaime_F_HD/mmia_2020'ssd_path = '/Users/jaimemorandominguez/Desktop/test_descarga_GLM'#ssd_path = '/media/lrg'# Path where MMIA's .cdf files are located#MMIA_files_path = '/Volumes/Jaime_F_HD/mmia_2020/mmia_20'MMIA_files_path = '/Users/jaimemorandominguez/Desktop/test_cdf'#MMIA_files_path = '/media/lrg/mmia_20'### GLM #### Time in seconds to analyze GLM and MMIA before and after LINET's time snippetcropping_margin = 0.5# Plus of angle in latitude and longitude to snip GLM dataGLM_radius = 400 # [km]angle_margin = GLM_radius / 111.11 # or a given value in degrees [ยบ]# Boolean variable for downloading GLM .nc files from Google Cloud Storagepre_downloaded_GLM = True# Boolean variable for pre-extracted filespre_extracted_GLM = True# Boolean variable for integrating GLM signals if not pre-donepre_integrated_GLM = True### MMIA #### Boolean variable for pre-extracted filespre_extracted_MMIA = True# Boolean variable for conditioning MMIA data if not done beforepre_conditioned_MMIA = True# Maximum length in seconds of each triggertrigger_length = 2 # [s]# Threshold for MMIA signalmmia_threshold = 1.75   # [micro W / m^2]'''#####################################################           END OF USER INPUT DATA              #####################################################'''# New directories paths needed in the futuregeneral_variables_path = ssd_path + '/general_variables_bin'xcorr_bin = ssd_path + '/xcorr_bin'xcorr_figures = ssd_path + '/xcorr_figures'peaks_bin = ssd_path + '/peaks_bin'GLM_ordered_dir = ssd_path + '/glm_downl_nc_files'GLM_ordered_outputs = ssd_path + '/glm_txt'GLM_integrated_bin = ssd_path + '/glm_int_bin'MMIA_mats_path = ssd_path + '/mmia_mat'MMIA_filtered_bin = ssd_path + '/mmia_filt_bin'###### MMIA'S TRIGGER CHARACTERIZATION ######if first_execution == True:        pre_trigger_directories = False    pre_downloaded_GLM = False    pre_extracted_GLM = False    pre_integrated_GLM = False    pre_extracted_MMIA = False    pre_conditioned_MMIA = False    pre_xc = False    [matches, trigger_filenames] = TFG.get_MMIA_triggers(MMIA_files_path, trigger_length)        os.system('mkdir ' + general_variables_path)        # Saving 'matches' variable into a binary    f = open(general_variables_path+'/matches.pckl', 'wb')    pickle.dump(matches, f)    f.close()        # Saving 'trigger_filenames' variable into a binary    f = open(general_variables_path+'/trigger_filenames.pckl', 'wb')    pickle.dump(trigger_filenames, f)    f.close()    else:        # Uploading 'matches' from binary    f = open(general_variables_path+'/matches.pckl', 'rb')    matches = pickle.load(f)    f.close()        # Uploading 'trigger_filenames' from binary    f = open(general_variables_path+'/trigger_filenames.pckl', 'rb')    trigger_filenames = pickle.load(f)    f.close()if pre_trigger_directories == False:        TFG.create_MMIA_trigger_directories(matches, trigger_filenames, MMIA_files_path, ssd_path)################################################################################   From this point every step is made for every day with existing MMIA data###############################################################################for day in range(len(matches)):        print('******************************')    print('DAY %s' % matches[day])    print('******************************')        ###### MMIA'S DATA ORDERING, EXTRACTION, UPLOAD AND CONDITIONING ######    # File ordering and data extraction    if pre_extracted_MMIA == False:        [mmia_raw, trigger_limits] = TFG.extract_trigger_info(ssd_path, trigger_filenames, matches, day)    else:        print('All MMIA data was pre-extracted, uploading from %s...' % MMIA_mats_path)        [mmia_raw, trigger_limits] = TFG.upload_MMIA_mats(ssd_path, trigger_filenames, matches, day)        print('Done!\n')    if pre_conditioned_MMIA == False:        # Conditioning MMIA data for further analysis        MMIA_filtered = TFG.condition_MMIA_data(mmia_raw, matches, show_plots, mmia_threshold, day)                print('Saving MMIA conditioned data for day %s...' % matches[day])        if day == 0:            os.system('mkdir ' + MMIA_filtered_bin)        f = open(MMIA_filtered_bin + '/' + matches[day] + '.pckl', 'wb')        pickle.dump(MMIA_filtered, f)        f.close()        print('Done!\n')    else:        print('MMIA data was pre-conditioned. Uploading from %s/mmia_filtered_data.pckl...' % ssd_path)        f = open(MMIA_filtered_bin + '/' + matches[day] + '.pckl', 'rb')        MMIA_filtered = pickle.load(f)        f.close()        print('Done!\n')    del mmia_raw    ########### GLM'S DATA DOWNLOAD, EXTRACTION, UPLOAD AND CONDITIONING ###########    # Downloading GLM data from Google Cloud Services    if pre_downloaded_GLM == False:                TFG.download_GLM(ssd_path, trigger_filenames, MMIA_filtered, matches, day)    # Extracting GLM data into trigger .txt files    if pre_extracted_GLM == False:        TFG.extract_GLM(GLM_ordered_dir, GLM_ordered_outputs, trigger_limits, matches, MMIA_filtered, angle_margin, cropping_margin, day)    del trigger_limits    # Uploading and integrating GLM signal    if pre_integrated_GLM == False:                # Unifying all data in a structure of matrices        GLM_raw_data = TFG.unify_GLM_data(GLM_ordered_outputs, MMIA_filtered, matches, show_plots, day)        # Conditioning GLM data for further analysis        GLM_data = TFG.condition_GLM_data(GLM_raw_data, matches, show_plots, day)                del GLM_raw_data                print('Saving GLM integrated data for day %s...' % matches[day])        if day == 0:            os.system('mkdir ' + GLM_integrated_bin)        f = open(GLM_integrated_bin + '/' + matches[day] + '.pckl', 'wb')        pickle.dump(GLM_data, f)        f.close()        print('Done!\n')    else:        print('GLM data was pre-integrated. Uploading from %s/%s.pckl...' % (GLM_integrated_bin, matches[day]))        f = open(GLM_integrated_bin + '/' + matches[day] + '.pckl', 'rb')        GLM_data = pickle.load(f)        f.close()        print('Done!\n')    ########### CROSS-CORRELATION ###########    if pre_xc == False:                # Normalizing GLM data to cross-correlate with MMIA data        print('Normalizing GLM data for day %s...' % matches[day])        GLM_norm = [None] * len(GLM_data)        for j in range(len(GLM_data)):            if type(GLM_data[j]) == np.ndarray:                snippet = np.zeros((len(GLM_data[j]),2))                GLM_norm[j] = snippet                GLM_norm[j][:,0] = GLM_data[j][:,0]                GLM_norm[j][:,1] = TFG.normalize(GLM_data[j][:,1])        print('Done!')        print(' ')        # Normalizing MMIA data to cross-correlate with GLM data        print('Normalizing MMIA data for day %s...' % matches[day])        MMIA_norm = [None] * len(MMIA_filtered)        for j in range(len(MMIA_filtered)):            if type(MMIA_filtered[j]) == np.ndarray:                snippet = np.zeros((len(MMIA_filtered[j]),2))                MMIA_norm[j] = snippet                MMIA_norm[j][:,0] = MMIA_filtered[j][:,0]                MMIA_norm[j][:,1] = TFG.normalize(MMIA_filtered[j][:,1])        print('Done!')        print(' ')        # Cross-correlating snippets        show_plots = True        [GLM_xcorr, MMIA_xcorr, GLM_xcorr_norm, MMIA_xcorr_norm, delays] = TFG.cross_correlate_GLM_MMIA(GLM_data, MMIA_filtered, GLM_norm, MMIA_norm, matches, show_plots, day, xcorr_figures)        del GLM_norm        del MMIA_norm        show_plots = False        # Saving cross-correlated data        print('Saving cross-correlated data for day %s...' % matches[day])        if day == 0:            os.system('mkdir ' + xcorr_bin)        f = open(xcorr_bin + '/' + matches[day] + '.pckl', 'wb')        pickle.dump([GLM_xcorr, MMIA_xcorr, GLM_xcorr_norm, MMIA_xcorr_norm, delays], f)        f.close()        print('Done!\n')    else:        print('GLM and MMIA data for day %d was pre-correlated. Uploading from %s/%s.pckl...' % (matches[day], xcorr_bin, matches[day]))        f = open(xcorr_bin + '/' + matches[day] + '.pckl', 'rb')        [GLM_xcorr, MMIA_xcorr, GLM_xcorr_norm, MMIA_xcorr_norm, delays] = pickle.load(f)        f.close()        print('Done!\n')    del GLM_data    del MMIA_filtered    ########### PEAK DETECTION AND COMPARISON ###########    # Getting peaks from cross-correlated signals    [GLM_peaks, MMIA_peaks] = TFG.get_GLM_MMIA_peaks(GLM_xcorr, MMIA_xcorr, GLM_xcorr_norm, MMIA_xcorr_norm, matches, show_plots, day)        print('Saving peak positions for day %s...' % matches[day])    if day == 0:        os.system('mkdir ' + peaks_bin)    f = open(peaks_bin + '/' + matches[day] + '.pckl', 'wb')    pickle.dump([GLM_peaks, MMIA_peaks], f)    f.close()    print('Done!')    print(' ')        '''    # Getting matching peaks    matching_peaks = TFG.get_peak_matches(GLM_xcorr, MMIA_xcorr, GLM_peaks, MMIA_peaks, show_plots, matches)        # Getting delay statistics    [total_snippets, avg_all, std_all, avg_MMIA_delay, std_MMIA_delay, avg_GLM_delay, std_GLM_delay, MMIA_delays, GLM_delays, no_delays] = TFG.study_delays(delays, GLM_xcorr, MMIA_xcorr, show_plots)    '''